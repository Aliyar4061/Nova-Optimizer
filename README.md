# Nova-Optimizer
Nova is a hybrid optimizer combining Nesterov momentum, AMSGrad, and decoupled weight decay, with adaptive scaling and hybrid learning rates. It outperforms Adam and AdamW across benchmarks like CIFAR-10 and SST-2, offering faster convergence, better generalization, and stability.
